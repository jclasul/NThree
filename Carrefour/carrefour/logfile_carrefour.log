2017-12-06 16:15:36 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: carrefour)
2017-12-06 16:15:36 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'carrefour', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_IP': 4, 'DOWNLOAD_DELAY': 0.75, 'FEED_URI': 'carrefourtje.jsonlines', 'LOG_FILE': 'logfile_carrefour.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'carrefour.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['carrefour.spiders']}
2017-12-06 16:15:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2017-12-06 16:15:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-12-06 16:15:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-12-06 16:15:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-12-06 16:15:36 [scrapy.core.engine] INFO: Spider opened
2017-12-06 16:15:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-12-06 16:16:36 [scrapy.extensions.logstats] INFO: Crawled 64 pages (at 64 pages/min), scraped 55 items (at 55 items/min)
2017-12-06 16:20:17 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: carrefour)
2017-12-06 16:20:17 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'carrefour', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_IP': 4, 'DOWNLOAD_DELAY': 0.75, 'FEED_URI': 'carrefourtje.jsonlines', 'LOG_FILE': 'logfile_carrefour.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'carrefour.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['carrefour.spiders']}
2017-12-06 16:20:24 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: carrefour)
2017-12-06 16:20:24 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'carrefour', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_IP': 4, 'DOWNLOAD_DELAY': 0.75, 'FEED_URI': 'carrefourtje.jsonlines', 'LOG_FILE': 'logfile_carrefour.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'carrefour.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['carrefour.spiders']}
2017-12-06 16:20:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2017-12-06 16:20:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-12-06 16:20:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-12-06 16:20:25 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-12-06 16:20:25 [scrapy.core.engine] INFO: Spider opened
2017-12-06 16:20:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-12-06 16:21:25 [scrapy.extensions.logstats] INFO: Crawled 64 pages (at 64 pages/min), scraped 50 items (at 50 items/min)
2017-12-06 16:22:25 [scrapy.extensions.logstats] INFO: Crawled 128 pages (at 64 pages/min), scraped 109 items (at 59 items/min)
2017-12-06 16:23:25 [scrapy.extensions.logstats] INFO: Crawled 194 pages (at 66 pages/min), scraped 170 items (at 61 items/min)
2017-12-06 16:24:25 [scrapy.extensions.logstats] INFO: Crawled 258 pages (at 64 pages/min), scraped 224 items (at 54 items/min)
2017-12-06 16:25:25 [scrapy.extensions.logstats] INFO: Crawled 324 pages (at 66 pages/min), scraped 284 items (at 60 items/min)
2017-12-06 16:26:25 [scrapy.extensions.logstats] INFO: Crawled 387 pages (at 63 pages/min), scraped 343 items (at 59 items/min)
2017-12-06 16:27:25 [scrapy.extensions.logstats] INFO: Crawled 451 pages (at 64 pages/min), scraped 401 items (at 58 items/min)
2017-12-06 16:28:25 [scrapy.extensions.logstats] INFO: Crawled 515 pages (at 64 pages/min), scraped 461 items (at 60 items/min)
2017-12-06 16:29:25 [scrapy.extensions.logstats] INFO: Crawled 580 pages (at 65 pages/min), scraped 521 items (at 60 items/min)
2017-12-06 16:30:25 [scrapy.extensions.logstats] INFO: Crawled 643 pages (at 63 pages/min), scraped 579 items (at 58 items/min)
2017-12-06 16:31:25 [scrapy.extensions.logstats] INFO: Crawled 708 pages (at 65 pages/min), scraped 639 items (at 60 items/min)
2017-12-06 16:32:25 [scrapy.extensions.logstats] INFO: Crawled 773 pages (at 65 pages/min), scraped 699 items (at 60 items/min)
2017-12-06 16:33:25 [scrapy.extensions.logstats] INFO: Crawled 835 pages (at 62 pages/min), scraped 756 items (at 57 items/min)
2017-12-06 16:34:25 [scrapy.extensions.logstats] INFO: Crawled 903 pages (at 68 pages/min), scraped 814 items (at 58 items/min)
2017-12-06 16:35:25 [scrapy.extensions.logstats] INFO: Crawled 969 pages (at 66 pages/min), scraped 875 items (at 61 items/min)
2017-12-06 16:36:25 [scrapy.extensions.logstats] INFO: Crawled 1035 pages (at 66 pages/min), scraped 936 items (at 61 items/min)
2017-12-06 16:37:25 [scrapy.extensions.logstats] INFO: Crawled 1101 pages (at 66 pages/min), scraped 997 items (at 61 items/min)
2017-12-06 16:38:25 [scrapy.extensions.logstats] INFO: Crawled 1165 pages (at 64 pages/min), scraped 1056 items (at 59 items/min)
2017-12-06 16:39:25 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 63 pages/min), scraped 1114 items (at 58 items/min)
2017-12-06 16:40:25 [scrapy.extensions.logstats] INFO: Crawled 1292 pages (at 64 pages/min), scraped 1167 items (at 53 items/min)
2017-12-06 16:41:25 [scrapy.extensions.logstats] INFO: Crawled 1356 pages (at 64 pages/min), scraped 1227 items (at 60 items/min)
2017-12-06 16:42:25 [scrapy.extensions.logstats] INFO: Crawled 1424 pages (at 68 pages/min), scraped 1290 items (at 63 items/min)
2017-12-06 16:43:25 [scrapy.extensions.logstats] INFO: Crawled 1490 pages (at 66 pages/min), scraped 1351 items (at 61 items/min)
2017-12-06 16:44:25 [scrapy.extensions.logstats] INFO: Crawled 1554 pages (at 64 pages/min), scraped 1405 items (at 54 items/min)
2017-12-06 16:45:25 [scrapy.extensions.logstats] INFO: Crawled 1620 pages (at 66 pages/min), scraped 1466 items (at 61 items/min)
2017-12-06 16:46:25 [scrapy.extensions.logstats] INFO: Crawled 1684 pages (at 64 pages/min), scraped 1525 items (at 59 items/min)
2017-12-06 16:47:25 [scrapy.extensions.logstats] INFO: Crawled 1748 pages (at 64 pages/min), scraped 1584 items (at 59 items/min)
2017-12-06 16:48:25 [scrapy.extensions.logstats] INFO: Crawled 1814 pages (at 66 pages/min), scraped 1637 items (at 53 items/min)
2017-12-06 16:49:25 [scrapy.extensions.logstats] INFO: Crawled 1882 pages (at 68 pages/min), scraped 1699 items (at 62 items/min)
2017-12-06 16:49:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://webshop.carrefour.eu/nl/keuken/koken/koken-in-de-oven/ovenschaal-rechthoekig-35x25-cm-grijs>: HTTP status code is not handled or not allowed
2017-12-06 16:50:25 [scrapy.extensions.logstats] INFO: Crawled 1947 pages (at 65 pages/min), scraped 1759 items (at 60 items/min)
2017-12-06 16:50:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://webshop.carrefour.eu/nl/keuken/keukenhulpmiddelen/keukengerei-om-te-snijden/frietsnijder-18-8-rvs>: HTTP status code is not handled or not allowed
2017-12-06 16:51:25 [scrapy.extensions.logstats] INFO: Crawled 2015 pages (at 68 pages/min), scraped 1821 items (at 62 items/min)
2017-12-06 16:52:25 [scrapy.extensions.logstats] INFO: Crawled 2080 pages (at 65 pages/min), scraped 1881 items (at 60 items/min)
2017-12-06 16:53:25 [scrapy.extensions.logstats] INFO: Crawled 2144 pages (at 64 pages/min), scraped 1939 items (at 58 items/min)
2017-12-06 16:53:53 [scrapy.core.engine] INFO: Closing spider (finished)
2017-12-06 16:53:53 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (1943 items) in: carrefourtje.jsonlines
2017-12-06 16:53:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1400098,
 'downloader/request_count': 2175,
 'downloader/request_method_count/GET': 2175,
 'downloader/response_bytes': 76112148,
 'downloader/response_count': 2175,
 'downloader/response_status_count/200': 2173,
 'downloader/response_status_count/404': 2,
 'dupefilter/filtered': 6,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 12, 6, 15, 53, 53, 267931),
 'httperror/response_ignored_count': 2,
 'httperror/response_ignored_status_count/404': 2,
 'item_scraped_count': 1943,
 'log_count/INFO': 43,
 'request_depth_max': 1,
 'response_received_count': 2175,
 'scheduler/dequeued': 2174,
 'scheduler/dequeued/memory': 2174,
 'scheduler/enqueued': 2174,
 'scheduler/enqueued/memory': 2174,
 'start_time': datetime.datetime(2017, 12, 6, 15, 20, 25, 152826)}
2017-12-06 16:53:53 [scrapy.core.engine] INFO: Spider closed (finished)
2017-12-06 16:59:18 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: carrefour)
2017-12-06 16:59:18 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'carrefour', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_IP': 4, 'DOWNLOAD_DELAY': 0.75, 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter', 'LOGSTATS_INTERVAL': 0, 'LOG_FILE': 'logfile_carrefour.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'carrefour.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['carrefour.spiders']}
2017-12-06 16:59:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole']
2017-12-06 16:59:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-12-06 16:59:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-12-06 16:59:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-12-06 16:59:19 [scrapy.core.engine] INFO: Spider opened
2017-12-06 17:16:41 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: carrefour)
2017-12-06 17:16:41 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'carrefour', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_IP': 4, 'DOWNLOAD_DELAY': 0.75, 'FEED_URI': 'carrefourtest.jsonlines', 'LOG_FILE': 'logfile_carrefour.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'carrefour.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['carrefour.spiders']}
2017-12-06 17:16:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2017-12-06 17:16:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-12-06 17:16:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-12-06 17:16:41 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-12-06 17:16:41 [scrapy.core.engine] INFO: Spider opened
2017-12-06 17:16:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-12-06 17:17:21 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://webshop.carrefour.eu/nl/multimedia/informatica/tablets/summer-pack-tablet-galaxy-tab-a-2016-10-1-16gb-wi-fi-car-kit-wit>: HTTP status code is not handled or not allowed
2017-12-06 17:17:38 [scrapy.core.engine] INFO: Closing spider (finished)
2017-12-06 17:17:38 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (52 items) in: carrefourtest.jsonlines
2017-12-06 17:17:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 40181,
 'downloader/request_count': 61,
 'downloader/request_method_count/GET': 61,
 'downloader/response_bytes': 1974912,
 'downloader/response_count': 61,
 'downloader/response_status_count/200': 60,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 12, 6, 16, 17, 38, 506486),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'item_scraped_count': 52,
 'log_count/INFO': 9,
 'request_depth_max': 7,
 'response_received_count': 61,
 'scheduler/dequeued': 60,
 'scheduler/dequeued/memory': 60,
 'scheduler/enqueued': 60,
 'scheduler/enqueued/memory': 60,
 'start_time': datetime.datetime(2017, 12, 6, 16, 16, 41, 803248)}
2017-12-06 17:17:38 [scrapy.core.engine] INFO: Spider closed (finished)
2017-12-06 17:32:19 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: carrefour)
2017-12-06 17:32:19 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'carrefour', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_IP': 4, 'DOWNLOAD_DELAY': 0.75, 'FEED_FORMAT': 'json', 'FEED_URI': 'carrefourtestthishi.json', 'LOG_FILE': 'logfile_carrefour.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'carrefour.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['carrefour.spiders']}
2017-12-06 17:32:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2017-12-06 17:32:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-12-06 17:32:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-12-06 17:32:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-12-06 17:32:19 [scrapy.core.engine] INFO: Spider opened
2017-12-06 17:32:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-12-06 17:32:23 [scrapy.core.engine] INFO: Closing spider (finished)
2017-12-06 17:32:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2681,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 136665,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 12, 6, 16, 32, 23, 137484),
 'log_count/INFO': 7,
 'request_depth_max': 3,
 'response_received_count': 5,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2017, 12, 6, 16, 32, 19, 565600)}
2017-12-06 17:32:23 [scrapy.core.engine] INFO: Spider closed (finished)
2017-12-06 17:32:58 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: carrefour)
2017-12-06 17:32:58 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'carrefour', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_IP': 4, 'DOWNLOAD_DELAY': 0.75, 'FEED_FORMAT': 'json', 'FEED_URI': 'carrefourtestthishist.json', 'LOG_FILE': 'logfile_carrefour.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'carrefour.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['carrefour.spiders']}
2017-12-06 17:32:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2017-12-06 17:32:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-12-06 17:32:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-12-06 17:32:58 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-12-06 17:32:58 [scrapy.core.engine] INFO: Spider opened
2017-12-06 17:32:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-12-06 17:33:00 [scrapy.core.engine] INFO: Closing spider (finished)
2017-12-06 17:33:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1280,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 54516,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 12, 6, 16, 33, 0, 705640),
 'log_count/INFO': 7,
 'response_received_count': 3,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2017, 12, 6, 16, 32, 58, 762792)}
2017-12-06 17:33:00 [scrapy.core.engine] INFO: Spider closed (finished)
2017-12-06 17:33:19 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: carrefour)
2017-12-06 17:33:19 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'carrefour', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_IP': 4, 'DOWNLOAD_DELAY': 0.75, 'FEED_FORMAT': 'json', 'FEED_URI': 'carrefourtestthishist.json', 'LOG_FILE': 'logfile_carrefour.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'carrefour.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['carrefour.spiders']}
2017-12-06 17:33:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2017-12-06 17:33:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-12-06 17:33:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-12-06 17:33:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-12-06 17:33:19 [scrapy.core.engine] INFO: Spider opened
2017-12-06 17:33:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-12-06 17:33:19 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spiders\__init__.py", line 83, in start_requests
    yield Request(url, dont_filter=True)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\http\request\__init__.py", line 25, in __init__
    self._set_url(url)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\http\request\__init__.py", line 58, in _set_url
    raise ValueError('Missing scheme in request url: %s' % self._url)
ValueError: Missing scheme in request url: h
2017-12-06 17:33:19 [scrapy.core.engine] INFO: Closing spider (finished)
2017-12-06 17:33:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 12, 6, 16, 33, 19, 362388),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'start_time': datetime.datetime(2017, 12, 6, 16, 33, 19, 355386)}
2017-12-06 17:33:19 [scrapy.core.engine] INFO: Spider closed (finished)
2017-12-06 17:34:15 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: carrefour)
2017-12-06 17:34:15 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'carrefour', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_IP': 4, 'DOWNLOAD_DELAY': 0.75, 'FEED_FORMAT': 'json', 'FEED_URI': 'carrefourtestthishist.json', 'LOG_FILE': 'logfile_carrefour.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'carrefour.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['carrefour.spiders']}
2017-12-06 17:34:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2017-12-06 17:34:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-12-06 17:34:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-12-06 17:34:15 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-12-06 17:34:15 [scrapy.core.engine] INFO: Spider opened
2017-12-06 17:34:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-12-06 17:35:12 [scrapy.core.engine] INFO: Closing spider (finished)
2017-12-06 17:35:12 [scrapy.extensions.feedexport] INFO: Stored json feed (54 items) in: carrefourtestthishist.json
2017-12-06 17:35:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 41096,
 'downloader/request_count': 61,
 'downloader/request_method_count/GET': 61,
 'downloader/response_bytes': 1909908,
 'downloader/response_count': 61,
 'downloader/response_status_count/200': 61,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 12, 6, 16, 35, 12, 865697),
 'item_scraped_count': 54,
 'log_count/INFO': 8,
 'request_depth_max': 6,
 'response_received_count': 61,
 'scheduler/dequeued': 60,
 'scheduler/dequeued/memory': 60,
 'scheduler/enqueued': 60,
 'scheduler/enqueued/memory': 60,
 'start_time': datetime.datetime(2017, 12, 6, 16, 34, 15, 757773)}
2017-12-06 17:35:12 [scrapy.core.engine] INFO: Spider closed (finished)
2017-12-06 17:36:04 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: carrefour)
2017-12-06 17:36:04 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'carrefour', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_IP': 4, 'DOWNLOAD_DELAY': 0.75, 'FEED_FORMAT': 'json', 'FEED_URI': 'carrefourtestthishiszegegzt.json', 'LOG_FILE': 'logfile_carrefour.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'carrefour.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['carrefour.spiders']}
2017-12-06 17:36:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2017-12-06 17:36:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-12-06 17:36:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-12-06 17:36:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-12-06 17:36:04 [scrapy.core.engine] INFO: Spider opened
2017-12-06 17:36:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-12-06 17:37:04 [scrapy.extensions.logstats] INFO: Crawled 69 pages (at 69 pages/min), scraped 58 items (at 58 items/min)
2017-12-06 17:38:04 [scrapy.extensions.logstats] INFO: Crawled 133 pages (at 64 pages/min), scraped 112 items (at 54 items/min)
2017-12-06 17:39:04 [scrapy.extensions.logstats] INFO: Crawled 197 pages (at 64 pages/min), scraped 176 items (at 64 items/min)
2017-12-06 17:39:42 [scrapy.core.engine] INFO: Closing spider (finished)
2017-12-06 17:39:42 [scrapy.extensions.feedexport] INFO: Stored json feed (218 items) in: carrefourtestthishiszegegzt.json
2017-12-06 17:39:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 163268,
 'downloader/request_count': 239,
 'downloader/request_method_count/GET': 239,
 'downloader/response_bytes': 8200777,
 'downloader/response_count': 239,
 'downloader/response_status_count/200': 239,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 12, 6, 16, 39, 42, 760135),
 'item_scraped_count': 218,
 'log_count/INFO': 11,
 'request_depth_max': 13,
 'response_received_count': 239,
 'scheduler/dequeued': 238,
 'scheduler/dequeued/memory': 238,
 'scheduler/enqueued': 238,
 'scheduler/enqueued/memory': 238,
 'start_time': datetime.datetime(2017, 12, 6, 16, 36, 4, 342496)}
2017-12-06 17:39:42 [scrapy.core.engine] INFO: Spider closed (finished)
2017-12-06 17:40:57 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: carrefour)
2017-12-06 17:40:57 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'carrefour', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_IP': 4, 'DOWNLOAD_DELAY': 0.75, 'FEED_FORMAT': 'json', 'FEED_URI': 'carrefourtestthishiszegegjlegjlegzjlgzt.json', 'LOG_FILE': 'logfile_carrefour.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'carrefour.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['carrefour.spiders']}
2017-12-06 17:40:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2017-12-06 17:40:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-12-06 17:40:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-12-06 17:40:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-12-06 17:40:57 [scrapy.core.engine] INFO: Spider opened
2017-12-06 17:40:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-12-06 17:40:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/telecom/vaste-telefoons> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] > 9 and next_page is not None:
TypeError: '>' not supported between instances of 'str' and 'int'
2017-12-06 17:41:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/tv> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] > 9 and next_page is not None:
TypeError: '>' not supported between instances of 'str' and 'int'
2017-12-06 17:41:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/dvd-blu-ray> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] > 9 and next_page is not None:
TypeError: '>' not supported between instances of 'str' and 'int'
2017-12-06 17:41:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/foto> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] > 9 and next_page is not None:
TypeError: '>' not supported between instances of 'str' and 'int'
2017-12-06 17:41:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/camera> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] > 9 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 17:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/beamers> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] > 9 and next_page is not None:
TypeError: '>' not supported between instances of 'str' and 'int'
2017-12-06 17:41:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/geluid/radio-s-wekkers> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] > 9 and next_page is not None:
TypeError: '>' not supported between instances of 'str' and 'int'
2017-12-06 17:41:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/geluid/hoofdtelefoons> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] > 9 and next_page is not None:
TypeError: '>' not supported between instances of 'str' and 'int'
2017-12-06 17:41:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/geluid/home-cinema> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] > 9 and next_page is not None:
TypeError: '>' not supported between instances of 'str' and 'int'
2017-12-06 17:41:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/geluid/luidsprekers-docking-stations> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] > 9 and next_page is not None:
TypeError: '>' not supported between instances of 'str' and 'int'
2017-12-06 17:41:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/geluid/hi-fi> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] > 9 and next_page is not None:
TypeError: '>' not supported between instances of 'str' and 'int'
2017-12-06 17:41:09 [scrapy.core.engine] INFO: Closing spider (finished)
2017-12-06 17:41:09 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: carrefourtestthishiszegegjlegjlegzjlgzt.json
2017-12-06 17:41:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 6682,
 'downloader/request_count': 13,
 'downloader/request_method_count/GET': 13,
 'downloader/response_bytes': 390395,
 'downloader/response_count': 13,
 'downloader/response_status_count/200': 13,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 12, 6, 16, 41, 9, 973910),
 'item_scraped_count': 1,
 'log_count/ERROR': 11,
 'log_count/INFO': 8,
 'request_depth_max': 1,
 'response_received_count': 13,
 'scheduler/dequeued': 12,
 'scheduler/dequeued/memory': 12,
 'scheduler/enqueued': 12,
 'scheduler/enqueued/memory': 12,
 'spider_exceptions/TypeError': 11,
 'start_time': datetime.datetime(2017, 12, 6, 16, 40, 57, 913837)}
2017-12-06 17:41:09 [scrapy.core.engine] INFO: Spider closed (finished)
2017-12-06 17:42:17 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: carrefour)
2017-12-06 17:42:17 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'carrefour', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_IP': 4, 'DOWNLOAD_DELAY': 0.75, 'FEED_FORMAT': 'json', 'FEED_URI': 'carrefourtestthishiszegegjlegjleesqgesqgsqegesqg.json', 'LOG_FILE': 'logfile_carrefour.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'carrefour.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['carrefour.spiders']}
2017-12-06 17:42:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2017-12-06 17:42:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-12-06 17:42:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-12-06 17:42:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-12-06 17:42:17 [scrapy.core.engine] INFO: Spider opened
2017-12-06 17:42:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-12-06 17:42:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/telecom/vaste-telefoons> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] < 9 and next_page is not None:
TypeError: '<' not supported between instances of 'str' and 'int'
2017-12-06 17:42:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/tv> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] < 9 and next_page is not None:
TypeError: '<' not supported between instances of 'str' and 'int'
2017-12-06 17:42:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/dvd-blu-ray> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] < 9 and next_page is not None:
TypeError: '<' not supported between instances of 'str' and 'int'
2017-12-06 17:42:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/foto> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] < 9 and next_page is not None:
TypeError: '<' not supported between instances of 'str' and 'int'
2017-12-06 17:42:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/camera> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] < 9 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 17:42:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/beamers> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] < 9 and next_page is not None:
TypeError: '<' not supported between instances of 'str' and 'int'
2017-12-06 17:42:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/geluid/radio-s-wekkers> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] < 9 and next_page is not None:
TypeError: '<' not supported between instances of 'str' and 'int'
2017-12-06 17:42:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/geluid/hoofdtelefoons> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] < 9 and next_page is not None:
TypeError: '<' not supported between instances of 'str' and 'int'
2017-12-06 17:42:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/geluid/home-cinema> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] < 9 and next_page is not None:
TypeError: '<' not supported between instances of 'str' and 'int'
2017-12-06 17:42:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/geluid/luidsprekers-docking-stations> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] < 9 and next_page is not None:
TypeError: '<' not supported between instances of 'str' and 'int'
2017-12-06 17:42:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/geluid/hi-fi> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if re.findall(r'\d+', next_page)[-1] < 9 and next_page is not None:
TypeError: '<' not supported between instances of 'str' and 'int'
2017-12-06 17:42:28 [scrapy.core.engine] INFO: Closing spider (finished)
2017-12-06 17:42:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 6052,
 'downloader/request_count': 12,
 'downloader/request_method_count/GET': 12,
 'downloader/response_bytes': 358038,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 12,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 12, 6, 16, 42, 28, 42675),
 'log_count/ERROR': 11,
 'log_count/INFO': 7,
 'response_received_count': 12,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'spider_exceptions/TypeError': 11,
 'start_time': datetime.datetime(2017, 12, 6, 16, 42, 17, 257994)}
2017-12-06 17:42:28 [scrapy.core.engine] INFO: Spider closed (finished)
2017-12-06 17:43:07 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: carrefour)
2017-12-06 17:43:07 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'carrefour', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_IP': 4, 'DOWNLOAD_DELAY': 0.75, 'FEED_FORMAT': 'json', 'FEED_URI': 'carrefourtestthishiszegegjlegjleesqgesqgsqegesqg.json', 'LOG_FILE': 'logfile_carrefour.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'carrefour.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['carrefour.spiders']}
2017-12-06 17:43:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2017-12-06 17:43:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-12-06 17:43:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-12-06 17:43:07 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-12-06 17:43:07 [scrapy.core.engine] INFO: Spider opened
2017-12-06 17:43:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-12-06 17:43:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/camera> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 9 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 17:43:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/dvd-blu-ray?q=%3Arelevance&page=1> (referer: https://webshop.carrefour.eu/nl/multimedia/beeld/dvd-blu-ray)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 9 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 17:43:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/beamers?q=%3Arelevance&page=1> (referer: https://webshop.carrefour.eu/nl/multimedia/beeld/beamers)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 9 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 17:43:32 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://webshop.carrefour.eu/nl/multimedia/telecom/vaste-telefoons?q=%3Arelevance&page=5>: HTTP status code is not handled or not allowed
2017-12-06 17:43:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/tv?q=%3Arelevance&page=6> (referer: https://webshop.carrefour.eu/nl/multimedia/beeld/tv?q=%3Arelevance&page=5)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 9 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 17:44:07 [scrapy.extensions.logstats] INFO: Crawled 65 pages (at 65 pages/min), scraped 37 items (at 37 items/min)
2017-12-06 17:45:07 [scrapy.extensions.logstats] INFO: Crawled 130 pages (at 65 pages/min), scraped 101 items (at 64 items/min)
2017-12-06 17:46:07 [scrapy.extensions.logstats] INFO: Crawled 196 pages (at 66 pages/min), scraped 168 items (at 67 items/min)
2017-12-06 17:47:07 [scrapy.extensions.logstats] INFO: Crawled 261 pages (at 65 pages/min), scraped 229 items (at 61 items/min)
2017-12-06 17:47:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/geluid/home-cinema?q=%3Arelevance&page=2> (referer: https://webshop.carrefour.eu/nl/multimedia/geluid/home-cinema?q=%3Arelevance&page=1)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 9 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 17:47:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/geluid/hi-fi?q=%3Arelevance&page=5> (referer: https://webshop.carrefour.eu/nl/multimedia/geluid/hi-fi?q=%3Arelevance&page=4)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 9 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 17:47:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/geluid/radio-s-wekkers?q=%3Arelevance&page=8> (referer: https://webshop.carrefour.eu/nl/multimedia/geluid/radio-s-wekkers?q=%3Arelevance&page=7)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 9 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 17:48:07 [scrapy.extensions.logstats] INFO: Crawled 324 pages (at 63 pages/min), scraped 260 items (at 31 items/min)
2017-12-06 17:49:07 [scrapy.extensions.logstats] INFO: Crawled 390 pages (at 66 pages/min), scraped 326 items (at 66 items/min)
2017-12-06 17:54:23 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: carrefour)
2017-12-06 17:54:23 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'carrefour', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_IP': 4, 'DOWNLOAD_DELAY': 0.75, 'FEED_URI': 'finalcarrie.jsonlines', 'LOG_FILE': 'logfile_carrefour.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'carrefour.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['carrefour.spiders']}
2017-12-06 17:54:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2017-12-06 17:54:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-12-06 17:54:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-12-06 17:54:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-12-06 17:54:23 [scrapy.core.engine] INFO: Spider opened
2017-12-06 17:54:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-12-06 17:54:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/camera> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 7 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 17:54:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/dvd-blu-ray?q=%3Arelevance&page=1> (referer: https://webshop.carrefour.eu/nl/multimedia/beeld/dvd-blu-ray)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 7 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 17:55:23 [scrapy.extensions.logstats] INFO: Crawled 54 pages (at 54 pages/min), scraped 36 items (at 36 items/min)
2017-12-06 17:55:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/tv?q=%3Arelevance&page=6> (referer: https://webshop.carrefour.eu/nl/multimedia/beeld/tv?q=%3Arelevance&page=5)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 7 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 17:56:23 [scrapy.extensions.logstats] INFO: Crawled 118 pages (at 64 pages/min), scraped 97 items (at 61 items/min)
2017-12-06 17:56:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/telecom/vaste-telefoons?q=%3Arelevance&page=5> (referer: https://webshop.carrefour.eu/nl/multimedia/telecom/vaste-telefoons?q=%3Arelevance&page=4)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 7 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 17:57:23 [scrapy.extensions.logstats] INFO: Crawled 183 pages (at 65 pages/min), scraped 158 items (at 61 items/min)
2017-12-06 17:58:23 [scrapy.extensions.logstats] INFO: Crawled 249 pages (at 66 pages/min), scraped 225 items (at 67 items/min)
2017-12-06 17:59:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/geluid/home-cinema?q=%3Arelevance&page=2> (referer: https://webshop.carrefour.eu/nl/multimedia/geluid/home-cinema?q=%3Arelevance&page=1)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 7 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 17:59:23 [scrapy.extensions.logstats] INFO: Crawled 311 pages (at 62 pages/min), scraped 276 items (at 51 items/min)
2017-12-06 18:00:23 [scrapy.extensions.logstats] INFO: Crawled 375 pages (at 64 pages/min), scraped 338 items (at 62 items/min)
2017-12-06 18:01:23 [scrapy.extensions.logstats] INFO: Crawled 440 pages (at 65 pages/min), scraped 397 items (at 59 items/min)
2017-12-06 18:02:23 [scrapy.extensions.logstats] INFO: Crawled 505 pages (at 65 pages/min), scraped 457 items (at 60 items/min)
2017-12-06 18:03:23 [scrapy.extensions.logstats] INFO: Crawled 569 pages (at 64 pages/min), scraped 520 items (at 63 items/min)
2017-12-06 18:03:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/beamers?q=%3Arelevance&page=1> (referer: https://webshop.carrefour.eu/nl/multimedia/beeld/beamers)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 7 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 18:04:23 [scrapy.extensions.logstats] INFO: Crawled 631 pages (at 62 pages/min), scraped 576 items (at 56 items/min)
2017-12-06 18:04:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/geluid/hi-fi?q=%3Arelevance&page=5> (referer: https://webshop.carrefour.eu/nl/multimedia/geluid/hi-fi?q=%3Arelevance&page=4)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 7 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 18:05:08 [scrapy.core.engine] INFO: Closing spider (finished)
2017-12-06 18:05:08 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (625 items) in: finalcarrie.jsonlines
2017-12-06 18:05:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 445949,
 'downloader/request_count': 681,
 'downloader/request_method_count/GET': 681,
 'downloader/response_bytes': 24326022,
 'downloader/response_count': 681,
 'downloader/response_status_count/200': 681,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 12, 6, 17, 5, 8, 509895),
 'item_scraped_count': 625,
 'log_count/ERROR': 7,
 'log_count/INFO': 18,
 'request_depth_max': 7,
 'response_received_count': 681,
 'scheduler/dequeued': 680,
 'scheduler/dequeued/memory': 680,
 'scheduler/enqueued': 680,
 'scheduler/enqueued/memory': 680,
 'spider_exceptions/TypeError': 7,
 'start_time': datetime.datetime(2017, 12, 6, 16, 54, 23, 296448)}
2017-12-06 18:05:08 [scrapy.core.engine] INFO: Spider closed (finished)
2017-12-06 18:22:35 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: carrefour)
2017-12-06 18:22:35 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'carrefour', 'CONCURRENT_REQUESTS': 4, 'CONCURRENT_REQUESTS_PER_IP': 4, 'DOWNLOAD_DELAY': 0.75, 'FEED_URI': 'finalcarrie.jsonlines', 'LOG_FILE': 'logfile_carrefour.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'carrefour.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['carrefour.spiders']}
2017-12-06 18:22:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2017-12-06 18:22:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-12-06 18:22:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-12-06 18:22:35 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2017-12-06 18:22:35 [scrapy.core.engine] INFO: Spider opened
2017-12-06 18:22:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-12-06 18:22:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/camera> (referer: None)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 7 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 18:22:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/dvd-blu-ray?q=%3Arelevance&page=1> (referer: https://webshop.carrefour.eu/nl/multimedia/beeld/dvd-blu-ray)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 7 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 18:22:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/beeld/beamers?q=%3Arelevance&page=1> (referer: https://webshop.carrefour.eu/nl/multimedia/beeld/beamers)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 7 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
2017-12-06 18:22:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://webshop.carrefour.eu/nl/multimedia/telecom/vaste-telefoons?q=%3Arelevance&page=5> (referer: https://webshop.carrefour.eu/nl/multimedia/telecom/vaste-telefoons?q=%3Arelevance&page=4)
Traceback (most recent call last):
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\JCLA\carrefour\carrefour\spiders\carrefour_spider.py", line 67, in parse
    if int(re.findall(r'\d+', next_page)[-1]) < 7 and next_page is not None:
  File "C:\Users\JCLA\Anaconda3\envs\scrapingtool\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
TypeError: expected string or bytes-like object
